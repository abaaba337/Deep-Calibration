{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from src.PointwiseNet import PointwiseFNN\n",
    "from src.GridbasedNet import GridbasedFNN\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def Savepickle(obj, doc_path):\n",
    "  with open(doc_path, 'wb') as file:\n",
    "         dill.dump(obj, file)     \n",
    "\n",
    "def Readpickle(doc_path):\n",
    "    with open(doc_path, 'rb') as file:\n",
    "        return dill.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# European Call \n",
    "## Point-wise Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data_saved = Readpickle('./data/European/point_wise_training_data.pkl')\n",
    "paras = data_saved['paras']\n",
    "para_index = data_saved['para_index']\n",
    "dataset = data_saved['Xnormalized_data']\n",
    "train, validate, test = data_saved['train'], data_saved['validate'], data_saved['test']\n",
    "loader = { 'train' : DataLoader(train, batch_size=32, shuffle=True),\n",
    "           'validate': DataLoader(validate, batch_size=32, shuffle=True),\n",
    "           'test'  : DataLoader(test,  batch_size=32, shuffle=True) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# from src.PointwiseNet import PointwiseFNN\n",
    "point_wise_IV_approximator = PointwiseFNN(loader)\n",
    "point_wise_IV_approximator.Train(num_epochs=200, learning_rate=0.01, lr_step_size=10, min_lr =5e-4, abs_tolerance=0.001)\n",
    "point_wise_IV_approximator.Test(loader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reletive error on test\n",
    "point_wise_IV_approximator.eval()\n",
    "with torch.no_grad():\n",
    "    y_predict = point_wise_IV_approximator(test[:][0])\n",
    "    y_label = test[:][1]\n",
    "    relative_error = torch.abs((y_label - y_predict)/y_label).flatten().numpy() \n",
    "    absolute_error = torch.abs((y_label - y_predict)).flatten().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(relative_error, bins=30, range=(0, 0.1), alpha=0.5, color='blue', edgecolor='black')\n",
    "plt.xlabel('Relative_Error')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(absolute_error, bins=30, range=(0, 0.1), alpha=0.5, color='blue', edgecolor='black')\n",
    "plt.xlabel('Absolute_Error')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "result_saved = {\n",
    "    'state_dict' : point_wise_IV_approximator.state_dict(),\n",
    "    'train_loss' : point_wise_IV_approximator.train_loss,\n",
    "    'validate_loss' : point_wise_IV_approximator.validate_loss\n",
    "}\n",
    "\n",
    "# Savepickle(result_saved, './data/European/point_wise_training_result.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the model\n",
    "result_saved = Readpickle('./data/European/point_wise_training_result.pkl')\n",
    "point_wise_IV_approximator = PointwiseFNN(loader)\n",
    "point_wise_IV_approximator.load_state_dict(result_saved['state_dict'])\n",
    "point_wise_IV_approximator.train_loss = result_saved['train_loss']\n",
    "point_wise_IV_approximator.validate_loss = result_saved['validate_loss']\n",
    "point_wise_IV_approximator.Test(loader['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-based Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data_saved = Readpickle('./data/European/grid_based_training_data.pkl')\n",
    "paras = data_saved['paras']\n",
    "para_index = data_saved['para_index']\n",
    "dataset = data_saved['Xnormalized_data']\n",
    "train, validate, test = data_saved['train'], data_saved['validate'], data_saved['test']\n",
    "loader = { 'train' : DataLoader(train, batch_size=32, shuffle=True),\n",
    "           'validate': DataLoader(validate, batch_size=32, shuffle=True),\n",
    "           'test'  : DataLoader(test,  batch_size=32, shuffle=True) }\n",
    "recover_y_dim = data_saved['recover_y_dim'] # 88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "grid_based_IV_approximator = GridbasedFNN(loader)\n",
    "grid_based_IV_approximator.Train(num_epochs=15000, learning_rate=0.001, lr_step_size=100, min_lr =5e-4, abs_tolerance=0.001)\n",
    "grid_based_IV_approximator.Test(loader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_based_IV_approximator.eval()\n",
    "with torch.no_grad():\n",
    "    y_predict = grid_based_IV_approximator(test[:][0])\n",
    "    y_label = test[:][1]\n",
    "    relative_error = torch.abs((y_label - y_predict)/y_label) # .numpy().reshape(recover_y_dim)\n",
    "    relative_error_max = relative_error.max(dim=0)[0].numpy().reshape(recover_y_dim)\n",
    "    relative_error_mean = relative_error.mean(dim=0).numpy().reshape(recover_y_dim)\n",
    "    relative_error_median = relative_error.median(dim=0)[0].numpy().reshape(recover_y_dim)\n",
    "    \n",
    "    abs_error = torch.abs((y_label - y_predict)) # .numpy().reshape(recover_y_dim)\n",
    "    abs_error_max = abs_error.max(dim=0)[0].numpy().reshape(recover_y_dim)\n",
    "    abs_error_mean = abs_error.mean(dim=0).numpy().reshape(recover_y_dim)\n",
    "    abs_error_median = abs_error.median(dim=0)[0].numpy().reshape(recover_y_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "result_saved = {\n",
    "    'state_dict' : grid_based_IV_approximator.state_dict(),\n",
    "    'train_loss' : grid_based_IV_approximator.train_loss,\n",
    "    'validate_loss' : grid_based_IV_approximator.validate_loss\n",
    "}\n",
    "\n",
    "# Savepickle(result_saved, './data/European/grid_based_training_result.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the model\n",
    "result_saved = Readpickle('./data/European/grid_based_training_result.pkl')\n",
    "grid_based_IV_approximator = GridbasedFNN(loader)\n",
    "grid_based_IV_approximator.load_state_dict(result_saved['state_dict'])\n",
    "grid_based_IV_approximator.train_loss = result_saved['train_loss']\n",
    "grid_based_IV_approximator.validate_loss = result_saved['validate_loss']\n",
    "grid_based_IV_approximator.Test(loader['test'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
